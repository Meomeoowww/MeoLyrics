{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    },
    "colab": {
      "name": "Webscrapping for Genius.com.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Meomeoowww/MeoLyrics/blob/master/Webscrapping_for_Genius_com.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "93dnSgRDMAYK",
        "colab_type": "text"
      },
      "source": [
        "# Webscrapping for \"Genius\" on Rap Artists"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JIRrEDlXMAYV",
        "colab_type": "text"
      },
      "source": [
        "## Goals\n",
        "* Build a list of rappers (might be by coast or other)\n",
        "\n",
        "* Build a webscrapper to extract lyrics form Genius using their api\n",
        "\n",
        "* Export as csv for future use ..."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MdjzKh6UMAYY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import urllib3\n",
        "from urllib.parse import quote\n",
        "import json\n",
        "\n",
        "from bs4 import BeautifulSoup\n",
        "import re\n",
        "from io import StringIO\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-g_41j0PMAYe",
        "colab_type": "text"
      },
      "source": [
        "## Build a list of rappers (might be by coast or other)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5TtvsOM6MAYg",
        "colab_type": "code",
        "outputId": "c0f5da9d-5595-4f46-e804-14d113402504",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        }
      },
      "source": [
        "#all recognized hip hop artists from wikipedia\n",
        "\n",
        "init_lib2 = urllib3.PoolManager()\n",
        "wp2 = init_lib2.request('GET', 'https://en.wikipedia.org/wiki/List_of_hip_hop_musicians', assert_same_host=False)\n",
        "# wp2 = init_lib2.request('GET', 'https://en.wikipedia.org/wiki/List_of_West_Coast_hip_hop_artists')\n",
        "html2 = BeautifulSoup(wp2.data, \"html.parser\") # Extract the page's HTML as a string\n",
        "\n",
        "b = \"\"\n",
        "for i in range(0,27):\n",
        "    a = html2.find_all(\"div\", class_=\"div-col columns column-width\")[i].get_text()\n",
        "    b = b + a\n",
        "\n",
        "rappers = pd.read_csv(StringIO(b), sep='\\t', header=None)\n",
        "\n",
        "#flatten rappers list\n",
        "k = rappers.values.tolist()\n",
        "flatrap = []\n",
        "for n1 in k:\n",
        "    for n2 in n1:\n",
        "        flatrap.append(n2)\n",
        "flatrap[0]"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'03 Greedo'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cgpT5EkiMAYm",
        "colab_type": "text"
      },
      "source": [
        "## Build a webscrapper to extract lyrics form Genius using their api"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WefUdIv3MAYo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#client key\n",
        "cl_TK2 = 'X7D7eCcQjbLn9_clVs0mzhB-vg3bQv3-30zmDVVRbJW07w6m0YQHhAdSUvvJo9BV'\n",
        "base_url = \"https://api.genius.com/\"\n",
        "gen_search = \"search?q=\"\n",
        "art_search = \"artists/\"\n",
        "songs_search = \"songs/\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VtZH7exWMAYt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# define url scrapper from genius api\n",
        "def search_title(search):\n",
        "    #build query\n",
        "    req = base_url + gen_search + quote(search) # build str query\n",
        "    http = urllib3.PoolManager() # instantiate a poolmanager\n",
        "    request = http.request('GET', req, headers={\"Authorization\":\"Bearer \" + cl_TK2, \"User-Agent\": \"\"}) # request with heqder\n",
        "\n",
        "    data = json.loads(request.data.decode('utf-8'))\n",
        "        \n",
        "    title = []\n",
        "    for i in range(0, len(data['response']['hits'])):\n",
        "        title.append(data['response']['hits'][i]['result']['title'])\n",
        "    \n",
        "    return title"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o_zcXeBbMAYx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# define url scrapper from genius api\n",
        "def search_urls(search):\n",
        "    #build query\n",
        "    req = base_url + gen_search + quote(search) # build str query\n",
        "    http = urllib3.PoolManager() # instantiate a poolmanager\n",
        "    request = http.request('GET', req, headers={\"Authorization\":\"Bearer \" + cl_TK2, \"User-Agent\": \"\"}) # request with heqder\n",
        "\n",
        "    data = json.loads(request.data.decode('utf-8'))\n",
        "        \n",
        "    url = []\n",
        "    for i in range(0, len(data['response']['hits'])):\n",
        "        url.append(data['response']['hits'][i]['result']['url'])\n",
        "    \n",
        "    return url"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gma_jCJsMAY0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# lyrics scrapper based on url\n",
        "def search_lyrics(url):    \n",
        "    # collect lyrics    \n",
        "    init_lib = urllib3.PoolManager()\n",
        "    wp = init_lib.request('GET', url)\n",
        "    html = BeautifulSoup(wp.data, \"html.parser\") # Extract the page's HTML as a string\n",
        "\n",
        "    # Scrape lyrics from webpage\n",
        "    lyrics = html.find(\"div\", class_=\"lyrics\").get_text()\n",
        "    return lyrics"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-A72SWNEMAY6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def geniusscrapper(search):\n",
        "    r = search_urls(search)\n",
        "    \n",
        "    scrap = []\n",
        "    for i, j in enumerate(r):\n",
        "        l = search_lyrics(j)\n",
        "        scrap.append(l)\n",
        "    return scrap"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZwbLLQxzMAY-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# trial with Kendrick Lamar\n",
        "#kdot = geniusscrapper('Eminem')\n",
        "#print(ktit)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fs3sdSOhMAZB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "db = []\n",
        "songtitle = []\n",
        "art = []\n",
        "for r, n in enumerate(flatrap):\n",
        "    \n",
        "    a = geniusscrapper(n)\n",
        "    b = search_title(n)\n",
        "    \n",
        "    art.extend(n)\n",
        "    db.extend(a)\n",
        "    songtitle.extend(b)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NJeNHDuvMAZF",
        "colab_type": "code",
        "outputId": "11bf7de0-901f-4b1d-a90d-6750dcec3ace",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        }
      },
      "source": [
        "print(len(db))\n",
        "print(len(songtitle))\n",
        "print(len(art))\n",
        "\n",
        "adb = pd.DataFrame(db)\n",
        "asongtitle = pd.DataFrame(songtitle)\n",
        "aart = pd.DataFrame(art)\n",
        "\n",
        "adb.to_csv('adb.csv', index=True)\n",
        "asongtitle.to_csv('asongtitle.csv', index=True)\n",
        "aart.to_csv('aart.csv', index=True)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "13699\n",
            "13700\n",
            "12955\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}